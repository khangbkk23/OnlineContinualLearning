{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fba96a4",
   "metadata": {},
   "source": [
    "We will follow the structure:\n",
    "[Data Input/Stream]\n",
    "       ↓\n",
    "[Out-of-Distribution Detection]\n",
    "       ↓\n",
    "[Task Boundary Detector/Scheduler] → [Replay Buffer]\n",
    "       ↓                                 ↑↓\n",
    "[Neural Network Model] ←──────────────────┘\n",
    "       ↓\n",
    "[Regularization Mechanism]\n",
    "       ↓\n",
    "[Loss Function]\n",
    "       ↓\n",
    "[Training Loop/Optimizer]\n",
    "       ↓\n",
    "[Evaluation Module]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0d1d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "from typing import Dict, List, Optional, Union, Any\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7f9410",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc68e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class OnlineStreamDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wraps a dataset to simulate an online data stream for continual learning.\n",
    "    Each task is a slice of the dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_dataset, task_indices):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            base_dataset: The full dataset (e.g., torchvision.datasets.CIFAR10).\n",
    "            task_indices: List of indices for the current task's data.\n",
    "        \"\"\"\n",
    "        self.base_dataset = base_dataset\n",
    "        self.task_indices = task_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.task_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.task_indices[idx]\n",
    "        return self.base_dataset[real_idx]\n",
    "\n",
    "def create_online_stream_loaders(base_dataset, n_tasks, batch_size=32, shuffle=True):\n",
    "    \"\"\"\n",
    "    Splits the dataset into n_tasks and returns train and test loader functions.\n",
    "    \"\"\"\n",
    "    total_len = len(base_dataset)\n",
    "    indices = torch.randperm(total_len).tolist()\n",
    "    task_splits = [indices[i::n_tasks] for i in range(n_tasks)]\n",
    "\n",
    "    def train_loader_fn(task_id):\n",
    "        dataset = OnlineStreamDataset(base_dataset, task_splits[task_id])\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    def test_loader_fn(task_id):\n",
    "        dataset = OnlineStreamDataset(base_dataset, task_splits[task_id])\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader_fn, test_loader_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83b59f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "def create_offline_task_loaders(base_dataset, n_tasks, batch_size=64, shuffle=True):\n",
    "    \"\"\"\n",
    "    Splits the dataset into n_tasks for offline continual learning.\n",
    "    Returns two functions: train_loader_fn(task_id), test_loader_fn(task_id).\n",
    "    \"\"\"\n",
    "    total_len = len(base_dataset)\n",
    "    indices = torch.randperm(total_len).tolist()\n",
    "    task_splits = [indices[i::n_tasks] for i in range(n_tasks)]\n",
    "\n",
    "    class TaskDataset(Dataset):\n",
    "        def __init__(self, base_dataset, indices):\n",
    "            self.base_dataset = base_dataset\n",
    "            self.indices = indices\n",
    "        def __len__(self):\n",
    "            return len(self.indices)\n",
    "        def __getitem__(self, idx):\n",
    "            return self.base_dataset[self.indices[idx]]\n",
    "\n",
    "    def train_loader_fn(task_id):\n",
    "        dataset = TaskDataset(base_dataset, task_splits[task_id])\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    def test_loader_fn(task_id):\n",
    "        dataset = TaskDataset(base_dataset, task_splits[task_id])\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader_fn, test_loader_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9245c7fe",
   "metadata": {},
   "source": [
    "# Out of Distribution Detection\n",
    "For OOD task, we will consider 3 different approaches:\n",
    "- First, we will use Energy Based OOD Model (Deep Learning Approach)\n",
    "- Second, we will use Mahalanobis Distance OOD\n",
    "- Finally, we will use confidence based approach: Softmax-Based OOD\n",
    "## Energy Based OOD Detection\n",
    "Write a lot of function and calculation here\n",
    "The formular is E_c = - logsumexp(f_c(x)) to calculate energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f474c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class EnergyDetector:\n",
    "    def __init__(self):\n",
    "        self.tau = None\n",
    "\n",
    "    def fit(self, model, buffer, device, reg_cov=1e-5):\n",
    "        # No parameters to fit for energy-based detector, as it relies directly on the model's logits.\n",
    "        # This method is included for structural compatibility with MahalanobisDetector.\n",
    "        pass\n",
    "\n",
    "    def score(self, model, x, device):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits, _ = model(x) # Model returns (logits, features)\n",
    "        # Compute energy score: -logsumexp(logits, dim=1)\n",
    "        energies = -torch.logsumexp(logits, dim=1)\n",
    "        return energies\n",
    "\n",
    "    def detect(self, model, x, device):\n",
    "        return self.score(model, x, device) > self.tau\n",
    "\n",
    "    def set_threshold(self, model, buffer, device, false_positive_rate=0.2):\n",
    "        X_id, _ = buffer.get_all_data()\n",
    "        if X_id is None:\n",
    "            return\n",
    "        e_id = []\n",
    "        for i in range(0, len(X_id), 256):\n",
    "            batch = X_id[i:i+256].to(device).float()\n",
    "            e_id.append(self.score(model, batch, device))\n",
    "        e_id = torch.cat(e_id)\n",
    "        self.tau = torch.quantile(e_id, 1 - false_positive_rate).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6599b552",
   "metadata": {},
   "source": [
    "## Mahalanobis Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb0d4f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MahalanobisDetector:\n",
    "    def __init__(self):\n",
    "        self.class_means = {}\n",
    "        self.precision = None\n",
    "        self.tau = None\n",
    "\n",
    "    def fit(self, model, buffer, device, reg_cov=1e-5):\n",
    "        model.eval()\n",
    "        X, Y = buffer.get_all_data()\n",
    "        if X is None:\n",
    "            return\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        feats = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(X), 256):\n",
    "                batch = X[i:i+256].float()\n",
    "                f, _ = model(batch) # Model returns (logits, features)\n",
    "                feats.append(f)\n",
    "        feats = torch.cat(feats, dim=0)\n",
    "        for c in torch.unique(Y):\n",
    "            self.class_means[int(c.item())] = feats[Y==c].mean(dim=0)\n",
    "        centered = feats - torch.stack([self.class_means[int(y.item())] for y in Y])\n",
    "        cov = (centered.t() @ centered) / (len(Y)-1)\n",
    "        cov += reg_cov * torch.eye(cov.size(0)).to(device)\n",
    "        self.precision = torch.inverse(cov)\n",
    "\n",
    "    def score(self, model, x, device):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, f = model(x) # Model returns (logits, features)\n",
    "        dists = []\n",
    "        for mu in self.class_means.values():\n",
    "            diff = f - mu.unsqueeze(0)\n",
    "            dists.append(torch.sum(diff @ self.precision * diff, dim=1))\n",
    "        dists = torch.stack(dists, dim=1)\n",
    "        # print(f\"dists={dists}\")\n",
    "        return dists.min(dim=1)[0]\n",
    "\n",
    "    def detect(self, model, x, device):\n",
    "        return self.score(model, x, device) > self.tau\n",
    "\n",
    "    def set_threshold(self, model, buffer, device, false_positive_rate=0.2):\n",
    "        X_id, _ = buffer.get_all_data()\n",
    "        if X_id is None:\n",
    "            return\n",
    "        d_id = []\n",
    "        for i in range(0, len(X_id), 256):\n",
    "            d_id.append(self.score(model, X_id[i:i+256].to(device), device))\n",
    "        d_id = torch.cat(d_id)\n",
    "        self.tau = torch.quantile(d_id, 1 - false_positive_rate).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a8ce7b",
   "metadata": {},
   "source": [
    "## Softmax Based OOD Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "513b3ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SoftmaxDetector:\n",
    "    def __init__(self):\n",
    "        self.tau = None\n",
    "\n",
    "    def fit(self, model, buffer, device, reg_cov=1e-5):\n",
    "        # No parameters to fit for softmax-based detector, as it relies directly on the model's logits.\n",
    "        # This method is included for structural compatibility with other detectors.\n",
    "        pass\n",
    "\n",
    "    def score(self, model, x, device):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits, _ = model(x) # Model returns (logits, features)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        max_probs = probs.max(dim=1)[0]\n",
    "        # Score is -max_prob: lower (more negative) for ID (high confidence), higher (less negative) for OOD (low confidence)\n",
    "        return -max_probs\n",
    "\n",
    "    def detect(self, model, x, device):\n",
    "        return self.score(model, x, device) > self.tau\n",
    "\n",
    "    def set_threshold(self, model, buffer, device, false_positive_rate=0.2):\n",
    "        X_id, _ = buffer.get_all_data()\n",
    "        if X_id is None:\n",
    "            return\n",
    "        s_id = []\n",
    "        for i in range(0, len(X_id), 256):\n",
    "            batch = X_id[i:i+256].to(device).float()\n",
    "            s_id.append(self.score(model, batch, device))\n",
    "        s_id = torch.cat(s_id)\n",
    "        self.tau = torch.quantile(s_id, 1 - false_positive_rate).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a46584",
   "metadata": {},
   "source": [
    "# Task Boundary Detector\n",
    "For this one, we may disable in Offline CL\n",
    "## Loss Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fea13648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "class LossBasedTaskBoundaryDetector:\n",
    "    \"\"\"A module for detecting task boundaries in online CL using loss-based signals.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, loss_fn=nn.CrossEntropyLoss(), window_size=100, \n",
    "                 threshold_factor=2.0, buffer_size=1000):\n",
    "        \"\"\"\n",
    "        Initialize the task boundary detector.\n",
    "        \n",
    "        Args:\n",
    "            model: PyTorch model (nn.Module) to monitor for loss changes.\n",
    "            loss_fn: Loss function (default: CrossEntropyLoss).\n",
    "            window_size: Number of samples for sliding window loss averaging.\n",
    "            threshold_factor: Multiplier for dynamic threshold (mean + factor * std).\n",
    "            buffer_size: Maximum size of replay buffer for storing past task samples.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.window_size = window_size\n",
    "        self.threshold_factor = threshold_factor\n",
    "        self.buffer_size = buffer_size\n",
    "        \n",
    "        # Track losses in a sliding window\n",
    "        self.loss_window = deque(maxlen=window_size)\n",
    "        self.replay_buffer = deque(maxlen=buffer_size)\n",
    "        self.task_id = 0  # Current task ID\n",
    "        self.mean_loss = 0.0\n",
    "        self.std_loss = 1.0  # Avoid division by zero\n",
    "        \n",
    "    def update_loss(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Compute and store loss for a batch of data.\n",
    "        \n",
    "        Args:\n",
    "            inputs: Input tensor (batch).\n",
    "            targets: Target tensor (batch).\n",
    "        \n",
    "        Returns:\n",
    "            float: Current batch loss.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits, _ = self.model(inputs) # Model returns (logits, features)\n",
    "            loss = self.loss_fn(logits, targets).item()\n",
    "        self.loss_window.append(loss)\n",
    "        \n",
    "        # Update running mean and std for dynamic threshold\n",
    "        if len(self.loss_window) >= self.window_size // 2:\n",
    "            self.mean_loss = np.mean(list(self.loss_window))\n",
    "            self.std_loss = np.std(list(self.loss_window)) or 1.0  # Avoid zero std\n",
    "        return loss\n",
    "    \n",
    "    def detect_boundary(self, loss):\n",
    "        \"\"\"\n",
    "        Check if the current loss indicates a task boundary.\n",
    "        \n",
    "        Args:\n",
    "            loss: Current batch loss.\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if a new task is detected, False otherwise.\n",
    "        \"\"\"\n",
    "        if len(self.loss_window) < self.window_size // 2:\n",
    "            return False  # Not enough data to detect reliably\n",
    "        \n",
    "        threshold = self.mean_loss + self.threshold_factor * self.std_loss\n",
    "        if loss > threshold:\n",
    "            self.task_id += 1\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def add_to_buffer(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Add samples to the replay buffer for the current task.\n",
    "        \n",
    "        Args:\n",
    "            inputs: Input tensor (batch).\n",
    "            targets: Target tensor (batch).\n",
    "        \"\"\"\n",
    "        for x, y in zip(inputs, targets):\n",
    "            if len(self.replay_buffer) < self.buffer_size:\n",
    "                self.replay_buffer.append((x.cpu(), y.cpu(), self.task_id))\n",
    "    \n",
    "    def get_replay_samples(self, batch_size):\n",
    "        \"\"\"\n",
    "        Retrieve a batch of samples from the replay buffer.\n",
    "        \n",
    "        Args:\n",
    "            batch_size: Number of samples to retrieve.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (inputs, targets, task_ids) or None if buffer is empty.\n",
    "        \"\"\"\n",
    "        if not self.replay_buffer:\n",
    "            return None\n",
    "        indices = np.random.choice(len(self.replay_buffer), \n",
    "                                 min(batch_size, len(self.replay_buffer)), \n",
    "                                 replace=False)\n",
    "        samples = [self.replay_buffer[i] for i in indices]\n",
    "        inputs, targets, task_ids = zip(*samples)\n",
    "        return (torch.stack(inputs), torch.stack(targets), torch.tensor(task_ids))\n",
    "    \n",
    "    def process_batch(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Process a batch of data: update loss, detect boundaries, and manage buffer.\n",
    "        \n",
    "        Args:\n",
    "            inputs: Input tensor (batch).\n",
    "            targets: Target tensor (batch).\n",
    "        \n",
    "        Returns:\n",
    "            dict: {\n",
    "                'loss': Current batch loss,\n",
    "                'new_task': Whether a new task was detected,\n",
    "                'task_id': Current task ID\n",
    "            }\n",
    "        \"\"\"\n",
    "        # Compute loss and update window\n",
    "        loss = self.update_loss(inputs, targets)\n",
    "        \n",
    "        # Detect task boundary\n",
    "        new_task = self.detect_boundary(loss)\n",
    "        \n",
    "        # Add to replay buffer\n",
    "        self.add_to_buffer(inputs, targets)\n",
    "        \n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'new_task': new_task,\n",
    "            'task_id': self.task_id\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83549b0",
   "metadata": {},
   "source": [
    "## AutoEncoder Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abecc38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"Simple autoencoder for task boundary detection.\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()  # Assuming normalized inputs [0, 1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "class AutoencoderBasedTaskBoundaryDetector:\n",
    "    \"\"\"A module for detecting task boundaries in online CL using autoencoder reconstruction errors.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim=128, window_size=100, \n",
    "                 threshold_factor=2.0, buffer_size=1000, lr=0.001):\n",
    "        \"\"\"\n",
    "        Initialize the autoencoder-based task boundary detector.\n",
    "        \n",
    "        Args:\n",
    "            input_dim: Flattened input dimension (e.g., 784 for MNIST 28x28).\n",
    "            hidden_dim: Hidden layer size for the autoencoder.\n",
    "            window_size: Number of samples for sliding window error averaging.\n",
    "            threshold_factor: Multiplier for dynamic threshold (mean + factor * std).\n",
    "            buffer_size: Maximum size of replay buffer for storing past task samples.\n",
    "            lr: Learning rate for autoencoder training.\n",
    "        \"\"\"\n",
    "        self.autoencoder = Autoencoder(input_dim, hidden_dim)\n",
    "        self.optimizer = torch.optim.Adam(self.autoencoder.parameters(), lr=lr)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.window_size = window_size\n",
    "        self.threshold_factor = threshold_factor\n",
    "        self.buffer_size = buffer_size\n",
    "        \n",
    "        # Track reconstruction errors in a sliding window\n",
    "        self.error_window = deque(maxlen=window_size)\n",
    "        self.replay_buffer = deque(maxlen=buffer_size)\n",
    "        self.task_id = 0  # Current task ID\n",
    "        self.mean_error = 0.0\n",
    "        self.std_error = 1.0  # Avoid division by zero\n",
    "        \n",
    "    def train_autoencoder(self, inputs, epochs=1):\n",
    "        \"\"\"\n",
    "        Train the autoencoder on a batch of inputs.\n",
    "        \n",
    "        Args:\n",
    "            inputs: Input tensor (batch).\n",
    "            epochs: Number of training epochs per batch.\n",
    "        \"\"\"\n",
    "        self.autoencoder.train()\n",
    "        for _ in range(epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.autoencoder(inputs)\n",
    "            loss = self.loss_fn(outputs, inputs)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "    \n",
    "    def compute_reconstruction_error(self, inputs):\n",
    "        \"\"\"\n",
    "        Compute reconstruction error for a batch of data.\n",
    "        \n",
    "        Args:\n",
    "            inputs: Input tensor (batch).\n",
    "        \n",
    "        Returns:\n",
    "            float: Average reconstruction error for the batch.\n",
    "        \"\"\"\n",
    "        self.autoencoder.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.autoencoder(inputs)\n",
    "            error = self.loss_fn(outputs, inputs).item()\n",
    "        self.error_window.append(error)\n",
    "        \n",
    "        # Update running mean and std for dynamic threshold\n",
    "        if len(self.error_window) >= self.window_size // 2:\n",
    "            self.mean_error = np.mean(list(self.error_window))\n",
    "            self.std_error = np.std(list(self.error_window)) or 1.0  # Avoid zero std\n",
    "        return error\n",
    "    \n",
    "    def detect_boundary(self, error):\n",
    "        \"\"\"\n",
    "        Check if the current reconstruction error indicates a task boundary.\n",
    "        \n",
    "        Args:\n",
    "            error: Current batch reconstruction error.\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if a new task is detected, False otherwise.\n",
    "        \"\"\"\n",
    "        if len(self.error_window) < self.window_size // 2:\n",
    "            return False  # Not enough data to detect reliably\n",
    "        \n",
    "        threshold = self.mean_error + self.threshold_factor * self.std_error\n",
    "        if error > threshold:\n",
    "            self.task_id += 1\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def add_to_buffer(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Add samples to the replay buffer for the current task.\n",
    "        \n",
    "        Args:\n",
    "            inputs: Input tensor (batch).\n",
    "            targets: Target tensor (batch).\n",
    "        \"\"\"\n",
    "        for x, y in zip(inputs, targets):\n",
    "            if len(self.replay_buffer) < self.buffer_size:\n",
    "                self.replay_buffer.append((x.cpu(), y.cpu(), self.task_id))\n",
    "    \n",
    "    def get_replay_samples(self, batch_size):\n",
    "        \"\"\"\n",
    "        Retrieve a batch of samples from the replay buffer.\n",
    "        \n",
    "        Args:\n",
    "            batch_size: Number of samples to retrieve.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (inputs, targets, task_ids) or None if buffer is empty.\n",
    "        \"\"\"\n",
    "        if not self.replay_buffer:\n",
    "            return None\n",
    "        indices = np.random.choice(len(self.replay_buffer), \n",
    "                                 min(batch_size, len(self.replay_buffer)), \n",
    "                                 replace=False)\n",
    "        samples = [self.replay_buffer[i] for i in indices]\n",
    "        inputs, targets, task_ids = zip(*samples)\n",
    "        return (torch.stack(inputs), torch.stack(targets), torch.tensor(task_ids))\n",
    "    \n",
    "    def process_batch(self, inputs, targets, train_ae=True):\n",
    "        \"\"\"\n",
    "        Process a batch of data: train autoencoder, compute error, detect boundaries, and manage buffer.\n",
    "        \n",
    "        Args:\n",
    "            inputs: Input tensor (batch, flattened).\n",
    "            targets: Target tensor (batch).\n",
    "            train_ae: Whether to train the autoencoder on this batch.\n",
    "        \n",
    "        Returns:\n",
    "            dict: {\n",
    "                'error': Reconstruction error,\n",
    "                'new_task': Whether a new task was detected,\n",
    "                'task_id': Current task ID\n",
    "            }\n",
    "        \"\"\"\n",
    "        # Train autoencoder if enabled\n",
    "        if train_ae:\n",
    "            self.train_autoencoder(inputs)\n",
    "        \n",
    "        # Compute reconstruction error\n",
    "        error = self.compute_reconstruction_error(inputs)\n",
    "        \n",
    "        # Detect task boundary\n",
    "        new_task = self.detect_boundary(error)\n",
    "        \n",
    "        # Add to replay buffer\n",
    "        self.add_to_buffer(inputs, targets)\n",
    "        \n",
    "        return {\n",
    "            'error': error,\n",
    "            'new_task': new_task,\n",
    "            'task_id': self.task_id\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f18b09",
   "metadata": {},
   "source": [
    "## Scheduled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f652303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "class ScheduledTaskBoundaryDetector:\n",
    "    \"\"\"A module for detecting task boundaries in online CL using a fixed schedule.\"\"\"\n",
    "    \n",
    "    def __init__(self, switch_interval=1000, buffer_size=1000):\n",
    "        \"\"\"\n",
    "        Initialize the scheduled task boundary detector.\n",
    "        \n",
    "        Args:\n",
    "            switch_interval: Number of samples after which to trigger a task boundary.\n",
    "            buffer_size: Maximum size of replay buffer for storing past task samples.\n",
    "        \"\"\"\n",
    "        self.switch_interval = switch_interval\n",
    "        self.buffer_size = buffer_size\n",
    "        \n",
    "        # Track sample count and task ID\n",
    "        self.sample_count = 0\n",
    "        self.task_id = 0\n",
    "        self.replay_buffer = deque(maxlen=buffer_size)\n",
    "    \n",
    "    def update_count(self, batch_size):\n",
    "        \"\"\"\n",
    "        Update the sample count based on the current batch size.\n",
    "        \n",
    "        Args:\n",
    "            batch_size: Number of samples in the current batch.\n",
    "        \"\"\"\n",
    "        self.sample_count += batch_size\n",
    "    \n",
    "    def detect_boundary(self):\n",
    "        \"\"\"\n",
    "        Check if the current sample count indicates a task boundary based on the schedule.\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if a new task is detected, False otherwise.\n",
    "        \"\"\"\n",
    "        if self.sample_count >= self.switch_interval:\n",
    "            self.sample_count = 0  # Reset counter\n",
    "            self.task_id += 1\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def add_to_buffer(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Add samples to the replay buffer for the current task.\n",
    "        \n",
    "        Args:\n",
    "            inputs: Input tensor (batch).\n",
    "            targets: Target tensor (batch).\n",
    "        \"\"\"\n",
    "        for x, y in zip(inputs, targets):\n",
    "            if len(self.replay_buffer) < self.buffer_size:\n",
    "                self.replay_buffer.append((x.cpu(), y.cpu(), self.task_id))\n",
    "    \n",
    "    def get_replay_samples(self, batch_size):\n",
    "        \"\"\"\n",
    "        Retrieve a batch of samples from the replay buffer.\n",
    "        \n",
    "        Args:\n",
    "            batch_size: Number of samples to retrieve.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (inputs, targets, task_ids) or None if buffer is empty.\n",
    "        \"\"\"\n",
    "        if not self.replay_buffer:\n",
    "            return None\n",
    "        indices = np.random.choice(len(self.replay_buffer), \n",
    "                                 min(batch_size, len(self.replay_buffer)), \n",
    "                                 replace=False)\n",
    "        samples = [self.replay_buffer[i] for i in indices]\n",
    "        inputs, targets, task_ids = zip(*samples)\n",
    "        return (torch.stack(inputs), torch.stack(targets), torch.tensor(task_ids))\n",
    "    \n",
    "    def process_batch(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Process a batch of data: update sample count, detect boundaries, and manage buffer.\n",
    "        \n",
    "        Args:\n",
    "            inputs: Input tensor (batch).\n",
    "            targets: Target tensor (batch).\n",
    "        \n",
    "        Returns:\n",
    "            dict: {\n",
    "                'error': None (for interface compatibility),\n",
    "                'new_task': Whether a new task was detected,\n",
    "                'task_id': Current task ID\n",
    "            }\n",
    "        \"\"\"\n",
    "        # Update sample count\n",
    "        batch_size = inputs.size(0)\n",
    "        self.update_count(batch_size)\n",
    "        \n",
    "        # Detect task boundary\n",
    "        new_task = self.detect_boundary()\n",
    "        \n",
    "        # Add to replay buffer\n",
    "        self.add_to_buffer(inputs, targets)\n",
    "        \n",
    "        return {\n",
    "            'error': None,  # No error metric in scheduled approach\n",
    "            'new_task': new_task,\n",
    "            'task_id': self.task_id\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e454ef5",
   "metadata": {},
   "source": [
    "# Replay Buffer\n",
    "This should be fit for Online Learning\n",
    "For Offline Learning, we can use some other choice provides more precision\n",
    "## Average Gradient Episodic Memory (A-GEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16a9b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class AGEMReplayBuffer:\n",
    "    def __init__(self, max_mem_size=None, device='cpu'):\n",
    "        self.max_mem_size = max_mem_size\n",
    "        self.exemplars = {}  # dict: task_id (int) -> (torch.Tensor X of shape (num_exemplars, C, H, W), torch.Tensor y of shape (num_exemplars,))\n",
    "        self.seen_tasks = set()\n",
    "        self.device = device\n",
    "\n",
    "    def construct_exemplar_set(self, model, X_new, y_new, task_id):\n",
    "        if task_id in self.seen_tasks:\n",
    "            return  # Skip if task already seen (assuming no duplicates)\n",
    "        self.seen_tasks.add(task_id)\n",
    "\n",
    "        if self.max_mem_size is not None:\n",
    "            m = self.max_mem_size // len(self.seen_tasks)\n",
    "            self.reduce_exemplar_set(m)\n",
    "            num_samples = min(m, len(X_new))\n",
    "            if num_samples > 0:\n",
    "                idx = torch.randperm(len(X_new))[:num_samples]\n",
    "                self.exemplars[task_id] = (X_new[idx].cpu(), y_new[idx].cpu())\n",
    "        else:\n",
    "            # Unlimited memory: store all\n",
    "            self.exemplars[task_id] = (X_new.cpu(), y_new.cpu())\n",
    "\n",
    "    def reduce_exemplar_set(self, m):\n",
    "        for t in list(self.exemplars.keys()):\n",
    "            if len(self.exemplars[t][0]) > m:\n",
    "                num_keep = min(m, len(self.exemplars[t][0]))\n",
    "                if num_keep > 0:\n",
    "                    idx = torch.randperm(len(self.exemplars[t][0]))[:num_keep]\n",
    "                    self.exemplars[t] = (self.exemplars[t][0][idx], self.exemplars[t][1][idx])\n",
    "                else:\n",
    "                    del self.exemplars[t]\n",
    "\n",
    "    def get_exemplar_set(self):\n",
    "        return self.get_all_data()\n",
    "\n",
    "    def get_exemplar_set_per_task(self, task_id):\n",
    "        if task_id in self.exemplars:\n",
    "            return self.exemplars[task_id][0], self.exemplars[task_id][1]\n",
    "        return None, None\n",
    "\n",
    "    def get_all_data(self):\n",
    "        X_list = []\n",
    "        Y_list = []\n",
    "        for t in self.exemplars:\n",
    "            X_list.append(self.exemplars[t][0])\n",
    "            Y_list.append(self.exemplars[t][1])\n",
    "        if not X_list:\n",
    "            return None, None\n",
    "        return torch.cat(X_list), torch.cat(Y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a56098c",
   "metadata": {},
   "source": [
    "## Incremental Classifier and Representation Learning (iCaRL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "395763ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class iCaRLReplayBuffer:\n",
    "    def __init__(self, max_mem_size=None, device='cpu'):\n",
    "        self.max_mem_size = max_mem_size\n",
    "        self.exemplars = {}  # dict: class_id (int) -> torch.Tensor of shape (num_exemplars, C, H, W)\n",
    "        self.class_to_task = {}  # dict: class_id -> task_id\n",
    "        self.seen_classes = set()\n",
    "        self.device = device\n",
    "\n",
    "    def _extract_features(self, model, X):\n",
    "        model.eval()\n",
    "        feats = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(X), 256):\n",
    "                batch = X[i:i+256].to(self.device).float()\n",
    "                out = model.immediate_forward(batch)\n",
    "                f = F.avg_pool2d(out, 8).view(batch.size(0), -1)\n",
    "                feats.append(f.cpu())\n",
    "        return torch.cat(feats)\n",
    "\n",
    "    def _herding(self, features, class_mean, m):\n",
    "        selected_idx = []\n",
    "        remaining_idx = list(range(features.size(0)))\n",
    "        current_mean = torch.zeros_like(class_mean)\n",
    "        for k in range(m):\n",
    "            best_dist = float('inf')\n",
    "            best_i = None\n",
    "            for idx in remaining_idx:\n",
    "                hypo_mean = (current_mean * k + features[idx]) / (k + 1)\n",
    "                dist = torch.norm(hypo_mean - class_mean).item()\n",
    "                if dist < best_dist:\n",
    "                    best_dist = dist\n",
    "                    best_i = idx\n",
    "            if best_i is not None:\n",
    "                selected_idx.append(best_i)\n",
    "                current_mean = (current_mean * k + features[best_i]) / (k + 1)\n",
    "                remaining_idx.remove(best_i)\n",
    "        return selected_idx\n",
    "\n",
    "    def construct_exemplar_set(self, model, X_new, y_new, task_id):\n",
    "        new_classes = torch.unique(y_new).tolist()\n",
    "        for c in new_classes:\n",
    "            if c in self.seen_classes:\n",
    "                continue  # Skip if class already seen (assuming no duplicates)\n",
    "            self.seen_classes.add(c)\n",
    "            self.class_to_task[c] = task_id\n",
    "\n",
    "        if self.max_mem_size is not None:\n",
    "            m = self.max_mem_size // len(self.seen_classes)\n",
    "            self.reduce_exemplar_set(m)\n",
    "            for c in new_classes:\n",
    "                mask = (y_new == c)\n",
    "                X_c = X_new[mask]\n",
    "                if len(X_c) <= m:\n",
    "                    self.exemplars[c] = X_c\n",
    "                else:\n",
    "                    features = self._extract_features(model, X_c)\n",
    "                    class_mean = features.mean(dim=0)\n",
    "                    selected_idx = self._herding(features, class_mean, m)\n",
    "                    self.exemplars[c] = X_c[selected_idx]\n",
    "        else:\n",
    "            # Unlimited memory: store all\n",
    "            for c in new_classes:\n",
    "                mask = (y_new == c)\n",
    "                X_c = X_new[mask]\n",
    "                self.exemplars[c] = X_c\n",
    "\n",
    "    def reduce_exemplar_set(self, m):\n",
    "        for c in list(self.exemplars.keys()):\n",
    "            if len(self.exemplars[c]) > m:\n",
    "                self.exemplars[c] = self.exemplars[c][:m]\n",
    "\n",
    "    def get_exemplar_set(self):\n",
    "        return self.get_all_data()\n",
    "\n",
    "    def get_exemplar_set_per_task(self, task_id):\n",
    "        X_list = []\n",
    "        Y_list = []\n",
    "        for c, ex in self.exemplars.items():\n",
    "            if self.class_to_task.get(c) == task_id:\n",
    "                X_list.append(ex)\n",
    "                Y_list.append(torch.full((len(ex),), c, dtype=torch.long))\n",
    "        if not X_list:\n",
    "            return None, None\n",
    "        return torch.cat(X_list), torch.cat(Y_list)\n",
    "\n",
    "    def get_all_data(self):\n",
    "        X_list = []\n",
    "        Y_list = []\n",
    "        for c, ex in self.exemplars.items():\n",
    "            X_list.append(ex)\n",
    "            Y_list.append(torch.full((len(ex),), c, dtype=torch.long))\n",
    "        if not X_list:\n",
    "            return None, None\n",
    "        return torch.cat(X_list), torch.cat(Y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2399284",
   "metadata": {},
   "source": [
    "## Dark Experience Replay (DER++)\n",
    "This one store logits too, consider rewrite the model structure (OR just keep it, logits is too computational expensive for A-GEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a77a90dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class DERppReplayBuffer:\n",
    "    def __init__(self, max_mem_size=None, device='cpu'):\n",
    "        self.max_mem_size = max_mem_size\n",
    "        self.exemplars = {}  # dict: task_id (int) -> (torch.Tensor X of shape (num_exemplars, C, H, W), torch.Tensor y of shape (num_exemplars,), torch.Tensor logits of shape (num_exemplars, n_classes))\n",
    "        self.seen_tasks = set()\n",
    "        self.device = device\n",
    "        self.n_classes = None  # To be set when storing exemplars to track output dimension\n",
    "\n",
    "    def construct_exemplar_set(self, model, X_new, y_new, task_id):\n",
    "        if task_id in self.seen_tasks:\n",
    "            return  # Skip if task already seen (assuming no duplicates)\n",
    "        self.seen_tasks.add(task_id)\n",
    "\n",
    "        # Compute logits for the new data\n",
    "        model.eval()\n",
    "        logits = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(X_new), 256):\n",
    "                batch = X_new[i:i+256].to(self.device).float()\n",
    "                batch_logits, _ = model(batch) # Model returns (logits, features)\n",
    "                logits.append(batch_logits.cpu())\n",
    "        logits = torch.cat(logits)\n",
    "\n",
    "        # Initialize n_classes if not set\n",
    "        if self.n_classes is None:\n",
    "            self.n_classes = logits.size(1)\n",
    "\n",
    "        if self.max_mem_size is not None:\n",
    "            m = self.max_mem_size // len(self.seen_tasks)\n",
    "            self.reduce_exemplar_set(m)\n",
    "            num_samples = min(m, len(X_new))\n",
    "            if num_samples > 0:\n",
    "                idx = torch.randperm(len(X_new))[:num_samples]\n",
    "                self.exemplars[task_id] = (X_new[idx].cpu(), y_new[idx].cpu(), logits[idx].cpu())\n",
    "        else:\n",
    "            # Unlimited memory: store all\n",
    "            self.exemplars[task_id] = (X_new.cpu(), y_new.cpu(), logits.cpu())\n",
    "\n",
    "    def reduce_exemplar_set(self, m):\n",
    "        for t in list(self.exemplars.keys()):\n",
    "            if len(self.exemplars[t][0]) > m:\n",
    "                num_keep = min(m, len(self.exemplars[t][0]))\n",
    "                if num_keep > 0:\n",
    "                    idx = torch.randperm(len(self.exemplars[t][0]))[:num_keep]\n",
    "                    self.exemplars[t] = (\n",
    "                        self.exemplars[t][0][idx],\n",
    "                        self.exemplars[t][1][idx],\n",
    "                        self.exemplars[t][2][idx]\n",
    "                    )\n",
    "                else:\n",
    "                    del self.exemplars[t]\n",
    "\n",
    "    def get_exemplar_set(self):\n",
    "        return self.get_all_data()\n",
    "\n",
    "    def get_exemplar_set_per_task(self, task_id):\n",
    "        if task_id in self.exemplars:\n",
    "            return self.exemplars[task_id][0], self.exemplars[task_id][1], self.exemplars[task_id][2]\n",
    "        return None, None, None\n",
    "\n",
    "    def get_all_data(self):\n",
    "        X_list = []\n",
    "        Y_list = []\n",
    "        logits_list = []\n",
    "        for t in self.exemplars:\n",
    "            X_list.append(self.exemplars[t][0])\n",
    "            Y_list.append(self.exemplars[t][1])\n",
    "            logits_list.append(self.exemplars[t][2])\n",
    "        if not X_list:\n",
    "            return None, None, None\n",
    "        return torch.cat(X_list), torch.cat(Y_list), torch.cat(logits_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84ac425",
   "metadata": {},
   "source": [
    "# Regularization Mechanism\n",
    "Let's go with EWC for Offline and Online then Online EWC and SI\n",
    "## Elastic Weight Consolidation (EWC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "429b198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from typing import Dict, List, Optional\n",
    "import os\n",
    "\n",
    "class EWC:\n",
    "    \"\"\"Implements Elastic Weight Consolidation for a single task.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: nn.Module, device: torch.device, ewc_lambda: float = 1.0):\n",
    "        \"\"\"Initialize EWC with a model and device.\n",
    "        \n",
    "        Args:\n",
    "            model (nn.Module): The neural network model.\n",
    "            device (torch.device): Device to store parameters and Fisher matrices.\n",
    "            ewc_lambda (float): Regularization strength.\n",
    "        \"\"\"\n",
    "        self.model = model  # Don't deepcopy, use reference to current model\n",
    "        self.device = device\n",
    "        self.ewc_lambda = ewc_lambda\n",
    "        self.params = {n: p.clone().detach().to(device) for n, p in model.named_parameters() if p.requires_grad}\n",
    "        self.fisher = None\n",
    "    \n",
    "    def update_in_training(self, *args, **kwargs):\n",
    "        \"\"\"EWC doesn't update during training - method for compatibility.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def update_per_task(self, dataloader, criterion, samples: int = 1000, *args, **kwargs):\n",
    "        \"\"\"Compute Fisher Information Matrix after task completion.\n",
    "        \n",
    "        Args:\n",
    "            dataloader: DataLoader for the task dataset.\n",
    "            criterion: Loss function (e.g., nn.CrossEntropyLoss).\n",
    "            samples (int): Number of samples to estimate Fisher information.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        fisher = {n: torch.zeros_like(p).to(self.device) for n, p in self.params.items()}\n",
    "        count = 0\n",
    "        \n",
    "        for data, target in dataloader:\n",
    "            if count >= samples:\n",
    "                break\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            self.model.zero_grad()\n",
    "            \n",
    "            logits, _ = self.model(data) # Model returns (logits, features)\n",
    "            \n",
    "            loss = criterion(logits, target)\n",
    "            loss.backward()\n",
    "            \n",
    "            for n, p in self.model.named_parameters():\n",
    "                if p.grad is not None and n in fisher:\n",
    "                    fisher[n] += p.grad.data.pow(2)\n",
    "            count += data.size(0)\n",
    "        \n",
    "        if count > 0:\n",
    "            self.fisher = {n: f / count for n, f in fisher.items()}\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        # Update stored parameters after computing Fisher\n",
    "        self.params = {n: p.clone().detach().to(self.device) for n, p in self.model.named_parameters() if p.requires_grad}\n",
    "    \n",
    "    def penalty(self):\n",
    "        \"\"\"Compute EWC regularization penalty.\"\"\"\n",
    "        if self.fisher is None:\n",
    "            return torch.tensor(0.0).to(self.device)\n",
    "        \n",
    "        penalty = torch.tensor(0.0).to(self.device)\n",
    "        for n, p in self.model.named_parameters():\n",
    "            if n in self.params and n in self.fisher:\n",
    "                penalty += (self.fisher[n] * (p - self.params[n]).pow(2)).sum()\n",
    "        return self.ewc_lambda * penalty\n",
    "    \n",
    "    def save(self, path: str):\n",
    "        \"\"\"Save parameters and Fisher matrix to a file.\n",
    "        \n",
    "        Args:\n",
    "            path (str): File path to save the EWC state.\n",
    "        \"\"\"\n",
    "        if self.fisher is None:\n",
    "            print(f\"Warning: Fisher matrix is None, saving empty EWC state to {path}\")\n",
    "        \n",
    "        # Ensure directory exists\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        \n",
    "        torch.save({\n",
    "            'params': {k: v.cpu() for k, v in self.params.items()},\n",
    "            'fisher': {k: v.cpu() for k, v in self.fisher.items()} if self.fisher is not None else None\n",
    "        }, path)\n",
    "        print(f\"EWC state saved to {path}\")\n",
    "\n",
    "    # Keep backward compatibility\n",
    "    def compute_fisher(self, dataloader, criterion, samples: int = 1000):\n",
    "        \"\"\"Backward compatibility - calls update_per_task.\"\"\"\n",
    "        return self.update_per_task(dataloader, criterion, samples)\n",
    "\n",
    "class PerTaskEWC:\n",
    "    \"\"\"Manages EWC for multiple tasks by loading EWC states from file paths.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: nn.Module, device: torch.device, ewc_lambda: float = 1.0, ewc_paths: List[str] = []):\n",
    "        \"\"\"Initialize PerTaskEWC with a model, device, and list of EWC file paths.\n",
    "        \n",
    "        Args:\n",
    "            model (nn.Module): The neural network model.\n",
    "            device (torch.device): Device to store parameters and Fisher matrices.\n",
    "            ewc_lambda (float): Regularization strength.\n",
    "            ewc_paths (List[str]): List of file paths containing EWC states.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.ewc_lambda = ewc_lambda\n",
    "        self.ewc_list = []\n",
    "        self.load_ewc_paths(ewc_paths)\n",
    "    \n",
    "    def load_ewc_paths(self, ewc_paths: List[str]):\n",
    "        \"\"\"Load EWC states from a list of file paths.\n",
    "        \n",
    "        Args:\n",
    "            ewc_paths (List[str]): List of file paths to EWC state dictionaries.\n",
    "        \"\"\"\n",
    "        self.ewc_list = []\n",
    "        for path in ewc_paths:\n",
    "            if os.path.exists(path):\n",
    "                state = torch.load(path, map_location=self.device)\n",
    "                ewc = EWC(self.model, self.device, self.ewc_lambda)\n",
    "                ewc.params = {n: p.to(self.device) for n, p in state['params'].items()}\n",
    "                ewc.fisher = {n: f.to(self.device) for n, f in state['fisher'].items()} if state['fisher'] is not None else None\n",
    "                self.ewc_list.append(ewc)\n",
    "                print(f\"Loaded EWC state from {path}\")\n",
    "            else:\n",
    "                print(f\"Warning: EWC file {path} not found.\")\n",
    "    \n",
    "    def update_in_training(self, *args, **kwargs):\n",
    "        \"\"\"PerTaskEWC doesn't update during training - method for compatibility.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def update_per_task(self, *args, **kwargs):\n",
    "        \"\"\"PerTaskEWC doesn't update per task - it loads from files.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def penalty(self):\n",
    "        \"\"\"Compute total EWC penalty across all tasks for the current model.\"\"\"\n",
    "        total_penalty = torch.tensor(0.0).to(self.device)\n",
    "        for ewc in self.ewc_list:\n",
    "            if ewc.fisher is not None:\n",
    "                penalty = torch.tensor(0.0).to(self.device)\n",
    "                for n, p in self.model.named_parameters():\n",
    "                    if n in ewc.params and n in ewc.fisher:\n",
    "                        penalty += (ewc.fisher[n] * (p - ewc.params[n]).pow(2)).sum()\n",
    "                total_penalty += penalty\n",
    "        return self.ewc_lambda * total_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274a997c",
   "metadata": {},
   "source": [
    "## Synaptic Intelligence (SI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8804caea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SynapticIntelligence(nn.Module):\n",
    "    def __init__(self, model, si_lambda=0.1):\n",
    "        super(SynapticIntelligence, self).__init__()\n",
    "        self.model = model\n",
    "        self.si_lambda = si_lambda  # Regularization strength\n",
    "        self.omega = {}  # Importance weights for parameters\n",
    "        self.prev_params = {}  # Store previous parameter values\n",
    "        self.param_importance = {}  # Accumulated importance\n",
    "        self.eps = 1e-8  # Small constant to avoid division by zero\n",
    "\n",
    "        # Initialize parameter tracking\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.omega[name] = torch.zeros_like(param)\n",
    "                self.prev_params[name] = param.data.clone().detach()\n",
    "                self.param_importance[name] = torch.zeros_like(param)\n",
    "\n",
    "    def update_in_training(self, *args, **kwargs):\n",
    "        \"\"\"Update importance during training (call after each backward pass).\n",
    "        Args are ignored for compatibility with other regularization methods.\n",
    "        \"\"\"\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None:\n",
    "                # Update importance: accumulate squared gradients\n",
    "                self.param_importance[name] += param.grad.data ** 2\n",
    "\n",
    "    def update_per_task(self, *args, **kwargs):\n",
    "        \"\"\"Compute importance weights (omega) after task training.\n",
    "        Args are ignored for compatibility with other regularization methods.\n",
    "        \"\"\"\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                # Omega is the normalized importance\n",
    "                total_importance = self.param_importance[name].sum() + self.eps\n",
    "                self.omega[name] = self.param_importance[name] / total_importance\n",
    "                # Reset importance for the next task\n",
    "                self.param_importance[name].zero_()\n",
    "                # Update previous parameters\n",
    "                self.prev_params[name].copy_(param.data.clone().detach())\n",
    "\n",
    "    def penalty(self):\n",
    "        \"\"\"Compute SI regularization penalty.\"\"\"\n",
    "        penalty = 0.0\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                # Penalty = sum(omega * (current_param - prev_param)^2)\n",
    "                delta = param - self.prev_params[name]\n",
    "                penalty += (self.omega[name] * (delta ** 2)).sum()\n",
    "        return self.si_lambda * penalty\n",
    "\n",
    "    # Keep backward compatibility\n",
    "    def update_importance(self, *args, **kwargs):\n",
    "        \"\"\"Backward compatibility - calls update_in_training.\"\"\"\n",
    "        return self.update_in_training(*args, **kwargs)\n",
    "    \n",
    "    def compute_omega(self):\n",
    "        \"\"\"Backward compatibility - calls update_per_task.\"\"\"\n",
    "        return self.update_per_task()\n",
    "\n",
    "    def save(self, path):\n",
    "        # This method doesn't require saving\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984026b6",
   "metadata": {},
   "source": [
    "## Online Elastic Weight Consolidation (Online EWC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3290ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class OnlineEWC(nn.Module):\n",
    "    def __init__(self, model, ewc_lambda=0.4, fisher_n=100):\n",
    "        super(OnlineEWC, self).__init__()\n",
    "        self.model = model\n",
    "        self.ewc_lambda = ewc_lambda  # Regularization strength\n",
    "        self.fisher_n = fisher_n  # Number of samples to estimate Fisher\n",
    "        self.prev_params = {}  # Store previous parameter values\n",
    "        self.fisher = {}  # Fisher Information Matrix (diagonal)\n",
    "        self.eps = 1e-8  # Small constant to avoid division by zero\n",
    "\n",
    "        # Initialize parameter tracking\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.prev_params[name] = param.data.clone().detach()\n",
    "                self.fisher[name] = torch.zeros_like(param)\n",
    "\n",
    "    def update_in_training(self, data_loader, criterion, *args, **kwargs):\n",
    "        \"\"\"Update Fisher Information Matrix during training.\n",
    "        Additional args are ignored for compatibility.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        fisher_acc = {name: torch.zeros_like(param) for name, param in self.model.named_parameters() if param.requires_grad}\n",
    "        n_samples = 0\n",
    "\n",
    "        for inputs, targets in data_loader:\n",
    "            if n_samples >= self.fisher_n:\n",
    "                break\n",
    "            inputs, targets = inputs.to(next(self.model.parameters()).device), targets.to(next(self.model.parameters()).device)\n",
    "            self.model.zero_grad()\n",
    "            \n",
    "            logits, _ = self.model(inputs) # Model returns (logits, features)\n",
    "\n",
    "            loss = criterion(logits, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            for name, param in self.model.named_parameters():\n",
    "                if param.requires_grad and param.grad is not None:\n",
    "                    fisher_acc[name] += param.grad.data ** 2\n",
    "            n_samples += inputs.size(0)\n",
    "\n",
    "        # Average Fisher and update previous parameters\n",
    "        for name in fisher_acc:\n",
    "            if n_samples > 0:\n",
    "                fisher_acc[name] /= n_samples\n",
    "                self.fisher[name] = fisher_acc[name]\n",
    "        \n",
    "        self.model.train()\n",
    "    \n",
    "    def update_per_task(self, *args, **kwargs):\n",
    "        \"\"\"Update previous parameters after task completion.\n",
    "        Args are ignored for compatibility with other regularization methods.\n",
    "        \"\"\"\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.prev_params[name].copy_(param.data.clone().detach())\n",
    "\n",
    "    def penalty(self):\n",
    "        \"\"\"Compute EWC regularization penalty.\"\"\"\n",
    "        penalty = 0.0\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                # Penalty = sum(Fisher * (current_param - prev_param)^2)\n",
    "                delta = param - self.prev_params[name]\n",
    "                penalty += (self.fisher[name] * (delta ** 2)).sum()\n",
    "        return self.ewc_lambda * penalty\n",
    "\n",
    "    # Keep backward compatibility\n",
    "    def update_fisher(self, data_loader, criterion):\n",
    "        \"\"\"Backward compatibility - calls update_in_training.\"\"\"\n",
    "        return self.update_in_training(data_loader, criterion)\n",
    "    \n",
    "    def save(self, path):\n",
    "        # This method doesn't require saving\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582b40c5",
   "metadata": {},
   "source": [
    "# Foundation Model\n",
    "For this model, we will build a simple CNN to deal with the task, and energy will act as the judge. Let's go through the structure:\n",
    "## Basic Convolutional Block\n",
    "This block simply take the input and return the output. We will follow normal structure: BatchNorm2d (stablizing data) -> ReLU (activate data) -> Conv2d (filter)\n",
    "## Network Block\n",
    "Wrapper for linking blocks as neural network\n",
    "## WideResNet\n",
    "This creates a wide ResNet to capture info. The depth is computed as (at least 2 blocks per Network Block) * 3 + 4 additional blocks (conv, bn, relu, fc). We use global average pooling to reduce the image (processed from neural network) to a single value per channel, then flip to 1D value vector, finally go through classifier. In additional, we add `immediate_forward` function for getting the pattern the model learned, and a `feature_list` function that saves immediate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1db21234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Basic block\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, dropout=0.0):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.dropout = dropout\n",
    "        self.equalInOut = (in_channels == out_channels)\n",
    "        # Add a shortcut to match dimensions\n",
    "        self.convShortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False) if not self.equalInOut else None\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # First convolutional layer finds simple patterns\n",
    "        if not self.equalInOut:\n",
    "            x = self.relu1(self.bn1(x))\n",
    "        else:\n",
    "            out = self.relu1(self.bn1(x))\n",
    "        if self.equalInOut:\n",
    "            out = self.relu2(self.bn2(self.conv1(out)))\n",
    "        else:\n",
    "            out = self.relu2(self.bn2(self.conv1(x)))\n",
    "        \n",
    "        # Dropout to prevent overfitting\n",
    "        if self.dropout > 0:\n",
    "            out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "\n",
    "        # Second convolutional layer finds more complex patterns\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        # Residual Connection\n",
    "        if not self.equalInOut:\n",
    "            return torch.add(out, self.convShortcut(x))\n",
    "        else:\n",
    "            return torch.add(out, x)\n",
    "\n",
    "# Network block    \n",
    "class NetworkBlock(nn.Module):\n",
    "    def __init__(self, block, in_channels, out_channels, n_blocks, stride=1, dropout=0.0):\n",
    "        super(NetworkBlock, self).__init__()\n",
    "        self.layer = self._make_layer(block, in_channels, out_channels, n_blocks, stride, dropout)\n",
    "\n",
    "    def _make_layer(self, block, in_channels, out_channels, n_blocks, stride, dropout):\n",
    "        layers = []\n",
    "        for i in range(n_blocks):\n",
    "            layers.append(block(in_channels if i == 0 else out_channels, out_channels, stride if i == 0 else 1, dropout))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "# OOD Model\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, depth, n_classes, widen_factor=1, dropout=0.0):\n",
    "        super(WideResNet, self).__init__()\n",
    "        n_channels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n",
    "        assert((depth - 4) % 6 == 0)\n",
    "        n_blocks = (depth - 4) // 6\n",
    "        block = BasicBlock\n",
    "        # Convolution before any block\n",
    "        self.conv1 = nn.Conv2d(3, n_channels[0], kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        # 1st block\n",
    "        self.block1 = NetworkBlock(block, n_channels[0], n_channels[1], n_blocks, stride=1, dropout=dropout)\n",
    "\n",
    "        # 2nd block\n",
    "        self.block2 = NetworkBlock(block, n_channels[1], n_channels[2], n_blocks, stride=2, dropout=dropout)\n",
    "\n",
    "        # 3rd block\n",
    "        self.block3 = NetworkBlock(block, n_channels[2], n_channels[3], n_blocks, stride=2, dropout=dropout)\n",
    "\n",
    "        # Global average pooling & classifier\n",
    "        self.bn1 = nn.BatchNorm2d(n_channels[3])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(n_channels[3], n_classes)\n",
    "        self.n_channels = n_channels[3]\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        features = out.view(-1, self.n_channels)  # Store features\n",
    "        logits = self.fc(features)\n",
    "        return logits, features\n",
    "\n",
    "    def immediate_forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8132f9",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "Simply correction + task regularization + specific module loss calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fd3a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional, Dict, Any, Union, List\n",
    "\n",
    "class ContinualLearningLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Unified loss module for continual learning that combines:\n",
    "    - Task loss (classification)\n",
    "    - Regularization penalties (EWC, SI, Online EWC)\n",
    "    - Replay loss\n",
    "    - OOD-specific losses\n",
    "    - Knowledge distillation loss\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 # Loss weights\n",
    "                 task_loss_weight: float = 1.0,\n",
    "                 regularization_weight: float = 1.0,\n",
    "                 replay_weight: float = 0.5,\n",
    "                 ood_weight: float = 0.1,\n",
    "                 distillation_weight: float = 0.5,\n",
    "                 \n",
    "                 # Task loss\n",
    "                 task_criterion: nn.Module = None,\n",
    "                 \n",
    "                 # Regularization mechanisms\n",
    "                 regularizers: List = None,\n",
    "                 \n",
    "                 # Replay buffer\n",
    "                 replay_buffer = None,\n",
    "                 \n",
    "                 # OOD detector\n",
    "                 ood_detector = None,\n",
    "                 \n",
    "                 # Distillation\n",
    "                 distillation_temperature: float = 4.0,\n",
    "                 \n",
    "                 # Device\n",
    "                 device: torch.device = torch.device('cpu')):\n",
    "        \"\"\"\n",
    "        Initialize the unified loss module.\n",
    "        \n",
    "        Args:\n",
    "            task_loss_weight: Weight for main task loss\n",
    "            regularization_weight: Weight for regularization penalties\n",
    "            replay_weight: Weight for replay loss\n",
    "            ood_weight: Weight for OOD-specific losses\n",
    "            distillation_weight: Weight for knowledge distillation\n",
    "            task_criterion: Loss function for main task (default: CrossEntropyLoss)\n",
    "            regularizers: List of regularization mechanisms\n",
    "            replay_buffer: Replay buffer instance\n",
    "            ood_detector: OOD detection module\n",
    "            distillation_temperature: Temperature for knowledge distillation\n",
    "            device: Computation device\n",
    "        \"\"\"\n",
    "        super(ContinualLearningLoss, self).__init__()\n",
    "        \n",
    "        # Loss weights\n",
    "        self.task_loss_weight = task_loss_weight\n",
    "        self.regularization_weight = regularization_weight\n",
    "        self.replay_weight = replay_weight\n",
    "        self.ood_weight = ood_weight\n",
    "        self.distillation_weight = distillation_weight\n",
    "        \n",
    "        # Loss components\n",
    "        self.task_criterion = task_criterion or nn.CrossEntropyLoss()\n",
    "        self.regularizers = regularizers or []\n",
    "        self.replay_buffer = replay_buffer\n",
    "        self.ood_detector = ood_detector\n",
    "        self.distillation_temperature = distillation_temperature\n",
    "        self.device = device\n",
    "        \n",
    "        # For storing previous model (knowledge distillation)\n",
    "        self.previous_model = None\n",
    "        \n",
    "    def set_previous_model(self, model):\n",
    "        \"\"\"Set previous model for knowledge distillation.\"\"\"\n",
    "        self.previous_model = model\n",
    "        \n",
    "    def _compute_task_loss(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute main task classification loss.\"\"\"\n",
    "        return self.task_criterion(logits, targets)\n",
    "    \n",
    "    def _compute_regularization_loss(self) -> torch.Tensor:\n",
    "        \"\"\"Compute total regularization penalty from all mechanisms.\"\"\"\n",
    "        total_penalty = torch.tensor(0.0, device=self.device)\n",
    "        \n",
    "        for regularizer in self.regularizers:\n",
    "            if hasattr(regularizer, 'penalty'):\n",
    "                penalty = regularizer.penalty()\n",
    "                total_penalty += penalty\n",
    "                \n",
    "        return total_penalty\n",
    "    \n",
    "    def _compute_replay_loss(self, model, replay_batch_size: int = 32) -> torch.Tensor:\n",
    "        \"\"\"Compute loss on replay buffer samples.\"\"\"\n",
    "        if self.replay_buffer is None:\n",
    "            return torch.tensor(0.0, device=self.device)\n",
    "        \n",
    "        # Get replay samples\n",
    "        if hasattr(self.replay_buffer, 'get_all_data'):\n",
    "            replay_data = self.replay_buffer.get_all_data()\n",
    "            if replay_data[0] is None:  # No replay data available\n",
    "                return torch.tensor(0.0, device=self.device)\n",
    "            \n",
    "            # Handle different replay buffer types\n",
    "            if len(replay_data) == 3:  # DER++ with logits\n",
    "                X_replay, y_replay, logits_replay = replay_data\n",
    "                # Sample a batch\n",
    "                if len(X_replay) > replay_batch_size:\n",
    "                    indices = torch.randperm(len(X_replay))[:replay_batch_size]\n",
    "                    X_replay = X_replay[indices].to(self.device)\n",
    "                    y_replay = y_replay[indices].to(self.device)\n",
    "                    logits_replay = logits_replay[indices].to(self.device)\n",
    "                else:\n",
    "                    X_replay = X_replay.to(self.device)\n",
    "                    y_replay = y_replay.to(self.device)\n",
    "                    logits_replay = logits_replay.to(self.device)\n",
    "                \n",
    "                # Compute current model output\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    current_logits, _ = model(X_replay) # Model returns (logits, features)\n",
    "                \n",
    "                # DER++ loss: classification + logits distillation\n",
    "                classification_loss = self.task_criterion(current_logits, y_replay)\n",
    "                distillation_loss = F.mse_loss(current_logits, logits_replay)\n",
    "                return classification_loss + 0.5 * distillation_loss\n",
    "                \n",
    "            else:  # Standard replay (A-GEM, iCaRL)\n",
    "                X_replay, y_replay = replay_data\n",
    "                # Sample a batch\n",
    "                if len(X_replay) > replay_batch_size:\n",
    "                    indices = torch.randperm(len(X_replay))[:replay_batch_size]\n",
    "                    X_replay = X_replay[indices].to(self.device)\n",
    "                    y_replay = y_replay[indices].to(self.device)\n",
    "                else:\n",
    "                    X_replay = X_replay.to(self.device)\n",
    "                    y_replay = y_replay.to(self.device)\n",
    "                \n",
    "                # Compute loss\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    replay_logits, _ = model(X_replay) # Model returns (logits, features)\n",
    "                \n",
    "                return self.task_criterion(replay_logits, y_replay)\n",
    "        \n",
    "        return torch.tensor(0.0, device=self.device)\n",
    "    \n",
    "    def _compute_ood_specific_loss(self, model, inputs: torch.Tensor, logits: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute OOD detector specific losses.\"\"\"\n",
    "        if self.ood_detector is None:\n",
    "            return torch.tensor(0.0, device=self.device)\n",
    "        \n",
    "        # Energy-based OOD loss\n",
    "        if hasattr(self.ood_detector, '__class__') and 'Energy' in self.ood_detector.__class__.__name__:\n",
    "            # Energy regularization: encourage lower energy for in-distribution samples\n",
    "            energy = -torch.logsumexp(logits, dim=1)\n",
    "            energy_loss = torch.mean(torch.relu(energy + 1.0))  # Encourage energy < -1\n",
    "            return energy_loss\n",
    "        \n",
    "        # Mahalanobis-based OOD loss\n",
    "        elif hasattr(self.ood_detector, '__class__') and 'Mahalanobis' in self.ood_detector.__class__.__name__:\n",
    "            # Feature space regularization\n",
    "            if hasattr(model, 'feature_list'):\n",
    "                _, features = model(inputs) # Model returns (logits, features)\n",
    "                if features:\n",
    "                    # Encourage compact feature representations\n",
    "                    feature_variance = torch.var(features[0].view(features[0].size(0), -1), dim=0)\n",
    "                    compactness_loss = torch.mean(feature_variance)\n",
    "                    return 0.1 * compactness_loss\n",
    "        \n",
    "        # Softmax-based OOD loss\n",
    "        elif hasattr(self.ood_detector, '__class__') and 'Softmax' in self.ood_detector.__class__.__name__:\n",
    "            # Confidence regularization: encourage high confidence for in-distribution\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            max_probs = probs.max(dim=1)[0]\n",
    "            confidence_loss = torch.mean(1.0 - max_probs)  # Encourage high confidence\n",
    "            return confidence_loss\n",
    "        \n",
    "        return torch.tensor(0.0, device=self.device)\n",
    "    \n",
    "    def _compute_distillation_loss(self, model, inputs: torch.Tensor, logits: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute knowledge distillation loss with previous model.\"\"\"\n",
    "        if self.previous_model is None:\n",
    "            return torch.tensor(0.0, device=self.device)\n",
    "        \n",
    "        self.previous_model.eval()\n",
    "        with torch.no_grad():\n",
    "            prev_logits, _ = self.previous_model(inputs) # Model returns (logits, features)\n",
    "        \n",
    "        # Knowledge distillation loss\n",
    "        T = self.distillation_temperature\n",
    "        current_soft = F.log_softmax(logits / T, dim=1)\n",
    "        previous_soft = F.softmax(prev_logits / T, dim=1)\n",
    "        \n",
    "        kd_loss = F.kl_div(current_soft, previous_soft, reduction='batchmean') * (T ** 2)\n",
    "        return kd_loss\n",
    "    \n",
    "    def forward(self, \n",
    "                model,\n",
    "                inputs: torch.Tensor, \n",
    "                targets: torch.Tensor,\n",
    "                logits: Optional[torch.Tensor] = None,\n",
    "                replay_batch_size: int = 32,\n",
    "                return_components: bool = False) -> Union[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Compute total loss combining all components.\n",
    "        \n",
    "        Args:\n",
    "            model: Current model\n",
    "            inputs: Input batch\n",
    "            targets: Target labels\n",
    "            logits: Pre-computed logits (optional, will compute if None)\n",
    "            replay_batch_size: Batch size for replay samples\n",
    "            return_components: Whether to return individual loss components\n",
    "            \n",
    "        Returns:\n",
    "            Total loss or dict of loss components if return_components=True\n",
    "        \"\"\"\n",
    "        # Compute logits if not provided\n",
    "        if logits is None:\n",
    "            logits, _ = model(inputs) # Model returns (logits, features)\n",
    "        \n",
    "        # Compute individual loss components\n",
    "        task_loss = self._compute_task_loss(logits, targets)\n",
    "        regularization_loss = self._compute_regularization_loss()\n",
    "        replay_loss = self._compute_replay_loss(model, replay_batch_size)\n",
    "        ood_loss = self._compute_ood_specific_loss(model, inputs, logits)\n",
    "        distillation_loss = self._compute_distillation_loss(model, inputs, logits)\n",
    "        \n",
    "        # Combine losses with weights\n",
    "        total_loss = (self.task_loss_weight * task_loss +\n",
    "                     self.regularization_weight * regularization_loss +\n",
    "                     self.replay_weight * replay_loss +\n",
    "                     self.ood_weight * ood_loss +\n",
    "                     self.distillation_weight * distillation_loss)\n",
    "        \n",
    "        if return_components:\n",
    "            return {\n",
    "                'total_loss': total_loss,\n",
    "                'task_loss': task_loss,\n",
    "                'regularization_loss': regularization_loss,\n",
    "                'replay_loss': replay_loss,\n",
    "                'ood_loss': ood_loss,\n",
    "                'distillation_loss': distillation_loss\n",
    "            }\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    def update_weights(self, **kwargs):\n",
    "        \"\"\"Update loss component weights dynamically.\"\"\"\n",
    "        for key, value in kwargs.items():\n",
    "            if hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "    \n",
    "    def add_regularizer(self, regularizer):\n",
    "        \"\"\"Add a new regularization mechanism.\"\"\"\n",
    "        self.regularizers.append(regularizer)\n",
    "    \n",
    "    def set_replay_buffer(self, replay_buffer):\n",
    "        \"\"\"Set or update the replay buffer.\"\"\"\n",
    "        self.replay_buffer = replay_buffer\n",
    "    \n",
    "    def set_ood_detector(self, ood_detector):\n",
    "        \"\"\"Set or update the OOD detector.\"\"\"\n",
    "        self.ood_detector = ood_detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b861553",
   "metadata": {},
   "source": [
    "# Online Continual Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d751acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class OnlineCLTrainer:\n",
    "    \"\"\"\n",
    "    Orchestrates Online Continual Learning training and evaluation using the best modules from above.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_loader_fn,  # function(task_id) -> DataLoader\n",
    "        test_loader_fn,   # function(task_id) -> DataLoader\n",
    "        device,\n",
    "        n_tasks,\n",
    "        n_classes,\n",
    "        evaluating_result=True,\n",
    "        epochs_per_task=1,\n",
    "        lr=0.01,\n",
    "        buffer_size=1000,\n",
    "        max_mem_size=2000,\n",
    "        regularizer_type='OnlineEWC'\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.n_tasks = n_tasks\n",
    "        self.n_classes = n_classes\n",
    "        self.evaluating_result = evaluating_result\n",
    "        self.epochs_per_task = epochs_per_task\n",
    "        self.lr = lr\n",
    "        self.buffer_size = buffer_size\n",
    "        self.max_mem_size = max_mem_size\n",
    "\n",
    "        # Replay Buffer: DER++ (best for online CL)\n",
    "        self.replay_buffer = DERppReplayBuffer(max_mem_size=max_mem_size, device=device)\n",
    "\n",
    "        # OOD Detector: Energy-based\n",
    "        self.ood_detector = EnergyDetector()\n",
    "\n",
    "        # Task Boundary Detector: Loss-based\n",
    "        self.task_boundary_detector = LossBasedTaskBoundaryDetector(\n",
    "            model=self.model, window_size=100, buffer_size=buffer_size\n",
    "        )\n",
    "\n",
    "        # Regularization: Online EWC or SI\n",
    "        if regularizer_type == 'OnlineEWC':\n",
    "            self.regularizer = OnlineEWC(self.model, ewc_lambda=0.4)\n",
    "        else:\n",
    "            self.regularizer = SynapticIntelligence(self.model, si_lambda=0.1)\n",
    "\n",
    "        # Loss Function\n",
    "        self.loss_fn = ContinualLearningLoss(\n",
    "            task_criterion=torch.nn.CrossEntropyLoss(),\n",
    "            regularizers=[self.regularizer],\n",
    "            replay_buffer=self.replay_buffer,\n",
    "            ood_detector=self.ood_detector,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Data loader functions\n",
    "        self.train_loader_fn = train_loader_fn\n",
    "        self.test_loader_fn = test_loader_fn\n",
    "\n",
    "        # Tracking\n",
    "        self.task_acc_history = []\n",
    "        self.time_acc_history = []\n",
    "        self.task_ids = []\n",
    "        self.time_steps = []\n",
    "\n",
    "    def evaluate(self, task_id):\n",
    "        self.model.eval()\n",
    "        loader = self.test_loader_fn(task_id)\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                logits, _ = self.model(x) # Model returns (logits, features)\n",
    "                pred = logits.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        acc = correct / total if total > 0 else 0.0\n",
    "        return acc\n",
    "\n",
    "    def train(self):\n",
    "        global_step = 0\n",
    "        for task_id in range(self.n_tasks):\n",
    "            train_loader = self.train_loader_fn(task_id)\n",
    "            optimizer = torch.optim.SGD(self.model.parameters(), lr=self.lr, momentum=0.9)\n",
    "            for epoch in range(self.epochs_per_task):\n",
    "                for x, y in train_loader:\n",
    "                    x, y = x.to(self.device), y.to(self.device)\n",
    "                    self.model.train()\n",
    "                    optimizer.zero_grad()\n",
    "                    logits, _ = self.model(x)  # Model returns (logits, features)\n",
    "                    loss = self.loss_fn(self.model, x, y, logits)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    # Update regularizer (OnlineEWC/SI)\n",
    "                    if hasattr(self.regularizer, 'update_in_training'):\n",
    "                        self.regularizer.update_in_training(train_loader, torch.nn.CrossEntropyLoss())\n",
    "                    # Update replay buffer\n",
    "                    self.replay_buffer.construct_exemplar_set(self.model, x.cpu(), y.cpu(), task_id)\n",
    "                    global_step += 1\n",
    "\n",
    "                # End of epoch: update regularizer per task\n",
    "                if hasattr(self.regularizer, 'update_per_task'):\n",
    "                    self.regularizer.update_per_task()\n",
    "            # Evaluate after each task\n",
    "            acc = self.evaluate(task_id)\n",
    "            self.task_acc_history.append(acc)\n",
    "            self.task_ids.append(task_id)\n",
    "            self.time_steps.append(global_step)\n",
    "            self.time_acc_history.append(acc)\n",
    "            if self.evaluating_result:\n",
    "                print(f\"Task {task_id+1}/{self.n_tasks} finished. Accuracy: {acc:.4f}\")\n",
    "            else:\n",
    "                print(f\"Task {task_id+1}/{self.n_tasks} finished.\")\n",
    "\n",
    "        # Final evaluation and plotting\n",
    "        self.plot_results()\n",
    "\n",
    "    def plot_results(self):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.time_steps, self.time_acc_history, marker='o', label='Accuracy over time')\n",
    "        plt.xlabel('Training Steps')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Online Continual Learning: Accuracy over Time')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(self.task_ids, self.task_acc_history, marker='s', color='orange', label='Accuracy per Task')\n",
    "        plt.xlabel('Task')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Online Continual Learning: Accuracy per Task')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Print summary metrics\n",
    "        avg_acc = sum(self.task_acc_history) / len(self.task_acc_history)\n",
    "        print(f\"\\nFinal Average Accuracy over {self.n_tasks} tasks: {avg_acc:.4f}\")\n",
    "        print(\"Accuracy per task:\", [f\"{a:.4f}\" for a in self.task_acc_history])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11733b69",
   "metadata": {},
   "source": [
    "# Offline Continual Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "819ecb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class OfflineCLTrainer:\n",
    "    \"\"\"\n",
    "    Orchestrates Offline Continual Learning training and evaluation using the best modules from above.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_loader_fn,  # function(task_id) -> DataLoader\n",
    "        test_loader_fn,   # function(task_id) -> DataLoader\n",
    "        device,\n",
    "        n_tasks,\n",
    "        n_classes,\n",
    "        evaluating_result=True,\n",
    "        epochs_per_task=10,\n",
    "        lr=0.01,\n",
    "        buffer_size=2000,\n",
    "        max_mem_size=4000,\n",
    "        regularizer_type='EWC'\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.n_tasks = n_tasks\n",
    "        self.n_classes = n_classes\n",
    "        self.evaluating_result = evaluating_result\n",
    "        self.epochs_per_task = epochs_per_task\n",
    "        self.lr = lr\n",
    "        self.buffer_size = buffer_size\n",
    "        self.max_mem_size = max_mem_size\n",
    "\n",
    "        # Replay Buffer: iCaRL (best for offline CL)\n",
    "        self.replay_buffer = iCaRLReplayBuffer(max_mem_size=max_mem_size, device=device)\n",
    "\n",
    "        # OOD Detector: Energy-based\n",
    "        self.ood_detector = EnergyDetector()\n",
    "\n",
    "        # Task Boundary Detector: Scheduled (offline, so schedule is known)\n",
    "        self.task_boundary_detector = ScheduledTaskBoundaryDetector(\n",
    "            switch_interval=buffer_size, buffer_size=buffer_size\n",
    "        )\n",
    "\n",
    "        # Regularization: EWC or SI\n",
    "        if regularizer_type == 'EWC':\n",
    "            self.regularizer = EWC(self.model, device, ewc_lambda=1.0)\n",
    "        else:\n",
    "            self.regularizer = SynapticIntelligence(self.model, si_lambda=0.1)\n",
    "\n",
    "        # Loss Function\n",
    "        self.loss_fn = ContinualLearningLoss(\n",
    "            task_criterion=torch.nn.CrossEntropyLoss(),\n",
    "            regularizers=[self.regularizer],\n",
    "            replay_buffer=self.replay_buffer,\n",
    "            ood_detector=self.ood_detector,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Data loader functions\n",
    "        self.train_loader_fn = train_loader_fn\n",
    "        self.test_loader_fn = test_loader_fn\n",
    "\n",
    "        # Tracking\n",
    "        self.task_acc_history = []\n",
    "        self.time_acc_history = []\n",
    "        self.task_ids = []\n",
    "        self.time_steps = []\n",
    "\n",
    "    def evaluate(self, task_id):\n",
    "        self.model.eval()\n",
    "        loader = self.test_loader_fn(task_id)\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                logits, _ = self.model(x)  # Model returns (logits, features)\n",
    "                pred = logits.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        acc = correct / total if total > 0 else 0.0\n",
    "        return acc\n",
    "\n",
    "    def train(self):\n",
    "        global_step = 0\n",
    "        for task_id in range(self.n_tasks):\n",
    "            train_loader = self.train_loader_fn(task_id)\n",
    "            optimizer = torch.optim.SGD(self.model.parameters(), lr=self.lr, momentum=0.9)\n",
    "            for epoch in range(self.epochs_per_task):\n",
    "                for x, y in train_loader:\n",
    "                    x, y = x.to(self.device), y.to(self.device)\n",
    "                    self.model.train()\n",
    "                    optimizer.zero_grad()\n",
    "                    logits, _ = self.model(x) # Model returns (logits, features)\n",
    "                    loss = self.loss_fn(self.model, x, y, logits)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    # Update regularizer (EWC/SI)\n",
    "                    if hasattr(self.regularizer, 'update_in_training'):\n",
    "                        self.regularizer.update_in_training()\n",
    "                    # Update replay buffer\n",
    "                    self.replay_buffer.construct_exemplar_set(self.model, x.cpu(), y.cpu(), task_id)\n",
    "                    global_step += 1\n",
    "\n",
    "            # End of task: update regularizer per task (EWC/SI)\n",
    "            if hasattr(self.regularizer, 'update_per_task'):\n",
    "                # For EWC, need dataloader and criterion\n",
    "                if isinstance(self.regularizer, EWC):\n",
    "                    self.regularizer.update_per_task(train_loader, torch.nn.CrossEntropyLoss())\n",
    "                else:\n",
    "                    self.regularizer.update_per_task()\n",
    "            # Evaluate after each task\n",
    "            acc = self.evaluate(task_id)\n",
    "            self.task_acc_history.append(acc)\n",
    "            self.task_ids.append(task_id)\n",
    "            self.time_steps.append(global_step)\n",
    "            self.time_acc_history.append(acc)\n",
    "            if self.evaluating_result:\n",
    "                print(f\"Task {task_id+1}/{self.n_tasks} finished. Accuracy: {acc:.4f}\")\n",
    "            else:\n",
    "                print(f\"Task {task_id+1}/{self.n_tasks} finished.\")\n",
    "\n",
    "        # Final evaluation and plotting\n",
    "        self.plot_results()\n",
    "\n",
    "    def plot_results(self):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.time_steps, self.time_acc_history, marker='o', label='Accuracy over time')\n",
    "        plt.xlabel('Training Steps')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Offline Continual Learning: Accuracy over Time')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(self.task_ids, self.task_acc_history, marker='s', color='orange', label='Accuracy per Task')\n",
    "        plt.xlabel('Task')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Offline Continual Learning: Accuracy per Task')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Print summary metrics\n",
    "        avg_acc = sum(self.task_acc_history) / len(self.task_acc_history)\n",
    "        print(f\"\\nFinal Average Accuracy over {self.n_tasks} tasks: {avg_acc:.4f}\")\n",
    "        print(\"Accuracy per task:\", [f\"{a:.4f}\" for a in self.task_acc_history])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9084243",
   "metadata": {},
   "source": [
    "# Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1224dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage pipeline for selecting Online or Offline Continual Learning\n",
    "\n",
    "def run_cl_pipeline(\n",
    "    cl_type,  # \"online\" or \"offline\"\n",
    "    model,\n",
    "    train_loader_fn,\n",
    "    test_loader_fn,\n",
    "    device,\n",
    "    n_tasks,\n",
    "    n_classes,\n",
    "    evaluating_result=True,\n",
    "    epochs_per_task=1,\n",
    "    lr=0.01,\n",
    "    buffer_size=1000,\n",
    "    max_mem_size=2000,\n",
    "    regularizer_type='OnlineEWC'\n",
    "):\n",
    "    if cl_type.lower() == \"online\":\n",
    "        trainer = OnlineCLTrainer(\n",
    "            model=model,\n",
    "            train_loader_fn=train_loader_fn,\n",
    "            test_loader_fn=test_loader_fn,\n",
    "            device=device,\n",
    "            n_tasks=n_tasks,\n",
    "            n_classes=n_classes,\n",
    "            evaluating_result=evaluating_result,\n",
    "            epochs_per_task=epochs_per_task,\n",
    "            lr=lr,\n",
    "            buffer_size=buffer_size,\n",
    "            max_mem_size=max_mem_size,\n",
    "            regularizer_type=regularizer_type\n",
    "        )\n",
    "    elif cl_type.lower() == \"offline\":\n",
    "        trainer = OfflineCLTrainer(\n",
    "            model=model,\n",
    "            train_loader_fn=train_loader_fn,\n",
    "            test_loader_fn=test_loader_fn,\n",
    "            device=device,\n",
    "            n_tasks=n_tasks,\n",
    "            n_classes=n_classes,\n",
    "            evaluating_result=evaluating_result,\n",
    "            epochs_per_task=epochs_per_task,\n",
    "            lr=lr,\n",
    "            buffer_size=buffer_size,\n",
    "            max_mem_size=max_mem_size,\n",
    "            regularizer_type='EWC' if regularizer_type == 'OnlineEWC' else regularizer_type\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"cl_type must be either 'online' or 'offline'.\")\n",
    "\n",
    "    trainer.train()\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "786cc606",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'CIFAR10' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     14\u001b[39m train_dataset = torchvision.datasets.CIFAR10(root=\u001b[33m'\u001b[39m\u001b[33m./data\u001b[39m\u001b[33m'\u001b[39m, train=\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m     15\u001b[39m                                            download=\u001b[38;5;28;01mTrue\u001b[39;00m, transform=transform)\n\u001b[32m     16\u001b[39m test_dataset = torchvision.datasets.CIFAR10(root=\u001b[33m'\u001b[39m\u001b[33m./data\u001b[39m\u001b[33m'\u001b[39m, train=\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[32m     17\u001b[39m                                           download=\u001b[38;5;28;01mTrue\u001b[39;00m, transform=transform)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m train_loader_fn, test_loader_fn = \u001b[43mcreate_offline_task_loaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m trainer = run_cl_pipeline(\n\u001b[32m     22\u001b[39m     cl_type=\u001b[33m\"\u001b[39m\u001b[33moffline\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m     model=model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m     regularizer_type=\u001b[33m'\u001b[39m\u001b[33mOnlineEWC\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     35\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mcreate_offline_task_loaders\u001b[39m\u001b[34m(base_dataset, n_tasks, batch_size, shuffle)\u001b[39m\n\u001b[32m      8\u001b[39m total_len = \u001b[38;5;28mlen\u001b[39m(base_dataset)\n\u001b[32m      9\u001b[39m indices = torch.randperm(total_len).tolist()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m task_splits = [indices[i::n_tasks] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_tasks\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTaskDataset\u001b[39;00m(Dataset):\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, base_dataset, indices):\n",
      "\u001b[31mTypeError\u001b[39m: 'CIFAR10' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model\n",
    "model = WideResNet(depth=28, n_classes=10, widen_factor=2, dropout=0.3)\n",
    "\n",
    "# Create dataset loaders (example with CIFAR-10)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                           download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, \n",
    "                                          download=True, transform=transform)\n",
    "\n",
    "train_loader_fn, test_loader_fn = create_offline_task_loaders(train_dataset, test_dataset, batch_size=64)\n",
    "\n",
    "trainer = run_cl_pipeline(\n",
    "    cl_type=\"offline\",\n",
    "    model=model,\n",
    "    train_loader_fn=train_loader_fn,\n",
    "    test_loader_fn=test_loader_fn,\n",
    "    device=device,\n",
    "    n_tasks=5,\n",
    "    n_classes=10,\n",
    "    evaluating_result=True,\n",
    "    epochs_per_task=1,\n",
    "    lr=0.01,\n",
    "    buffer_size=1000,\n",
    "    max_mem_size=2000,\n",
    "    regularizer_type='OnlineEWC'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-venv)",
   "language": "python",
   "name": "pytorch-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
